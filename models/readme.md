# Models

Description

|           | aka    | Layers | HH     | INT  | Heads | Non-embedding parameters | Parameters |
|-----------|--------|--------|--------|------|-------|--------------------------|------------|
| BERT_124M | base   | 12     | 768    | 3072 | 12    | 86M                      | 124M       |
| BERT_51M  | medium | 8      | 512    | 2048 | 8     | 25M                      | 51M        |
| BERT_16M  | mini   | 4      | 256    | 1024 | 4     | 3M                       | 16M        |

HH:hidden dimensions. INT: intermediate layer dimension. Heads: attention heads.


### Basque

|            |   125M                           |   25M                             |   5M                                  |
|------------|----------------------------------|-----------------------------------|---------------------------------------|
| BERT_124M  |                                  |                                   |                                       |
| BERT_51M   |                                  |                                   |                                       |
| BERT_16M   |                                  |                                   |                                       |

### Spanish

|            |   125M                           |   25M                             |   5M                                  |
|------------|----------------------------------|-----------------------------------|---------------------------------------|
| BERT_124M  |                                  |                                   |                                       |
| BERT_51M   |                                  |                                   |                                       |
| BERT_16M   |                                  |                                   |                                       |

### Swahili

|            |   125M                           |   25M                             |   5M                                  |
|------------|----------------------------------|-----------------------------------|---------------------------------------|
| BERT_124M  |                                  |                                   |                                       |
| BERT_51M   |                                  |                                   |                                       |
| BERT_16M   |                                  |                                   |                                       |

BERT_124M trained on 125M corpus (which is SotA in some tasks) also available at [HFðŸ¤— Datasets](https://huggingface.co/datasets/orai-nlp/bert-base-sw)!

### Finnish

|            |   125M                           |   25M                             |   5M                                  |
|------------|----------------------------------|-----------------------------------|---------------------------------------|
| BERT_124M  |                                  |                                   |                                       |
| BERT_51M   |                                  |                                   |                                       |
| BERT_16M   |                                  |                                   |                                       |
